{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc66fcb",
   "metadata": {},
   "source": [
    "# Forecasting solar flares using recurring neural networks for multi-class classification\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcde7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
    "                             roc_curve, precision_recall_curve, average_precision_score, \n",
    "                             fbeta_score, recall_score)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras import layers, Model, Input\n",
    "#from tensorflow.keras import layers, Model, Input\n",
    "import keras_tuner as kt\n",
    "import keras\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D, GRU\n",
    "\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras import Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a00a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw dataframe\n",
    "df = pd.read_csv(\"../data/data_flares.csv\")\n",
    "\n",
    "print(df.info())\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f77663",
   "metadata": {},
   "source": [
    "# Changing the dataframe to fit RNN\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9995b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'DATE' column is in datetime format\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze flare distribution over time\n",
    "\n",
    "# Number of flare-days per year\n",
    "df_flares = df.groupby(df['DATE'].dt.year)['flare_today'].agg(['sum'])\n",
    "print(df_flares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f018f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of days with flares (count should be 8760 [24*365] or 8784 for leap years)\n",
    "yearly_flares = df.groupby(df['DATE'].dt.year)['flare_today'].agg(['sum', 'count'])\n",
    "print(\"\\nDays with flare distribution by year:\")\n",
    "print(yearly_flares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b756e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the multi-class feature\n",
    "\n",
    "def label_from_counts(row):\n",
    "    if row[\"Flares: X\"] > 0:\n",
    "        return 3\n",
    "    elif row[\"Flares: M\"] > 0:\n",
    "        return 2\n",
    "    elif row[\"Flares: C\"] > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df[\"flare_class\"] = df.apply(label_from_counts, axis=1)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3baabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift target upward by 1 day\n",
    "df[\"flare_class\"] = df[\"flare_class\"].shift(-1)\n",
    "\n",
    "# Drop the last row (target is NaN)\n",
    "df = df.dropna(subset=[\"flare_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc08c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is too big to run the hyperparameter opitmization in my PC, so I am going to use a sample for this part\n",
    "df_short = df.sample(frac=1.00)\n",
    "print(df_short.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d513715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chronological split is important for time series\n",
    "df_short = df_short.sort_values('DATE').reset_index(drop=True)\n",
    "assert df_short['DATE'].is_monotonic_increasing\n",
    "\n",
    "print(df_short.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4442b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check all columns to drop some on the next step\n",
    "print(df_short.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4611633d",
   "metadata": {},
   "source": [
    "# Fitting the model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "feature_cols = [col for col in df.columns \n",
    "                if col not in ['DATE', \"flare_class\", \"flare_today\", \"flare_missing\"]]\n",
    "\n",
    "X = df_short[feature_cols].values\n",
    "y = df_short[\"flare_class\"].values\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequences (last N days)\n",
    "\n",
    "def build_sequences(df, seq_len=3):\n",
    "    X, y = [], []\n",
    "    values = df.drop(columns=['DATE', \"flare_class\", \"flare_today\", \"flare_missing\"]).values\n",
    "    targets = df[\"flare_class\"].values\n",
    "\n",
    "    for i in range(len(df) - seq_len):\n",
    "        X.append(values[i:i+seq_len])\n",
    "        y.append(targets[i+seq_len - 1])  # careful here\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_len = 14\n",
    "X_seq, y_seq = build_sequences(df, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "# Time series should not be randomly shuffled.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_seq, y_seq, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "print(f\"Percentage of positive cases in train: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "print(f\"Percentage of positive cases in test: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08597d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
    "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test_flat).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db3ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for flare class imbalance\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = {int(c): w for c, w in zip(classes, class_weights)}\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the training data\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "#print(f\"\\nAfter SMOTE:\")\n",
    "#print(f\"Training samples: {len(X_train_balanced)}\")\n",
    "#print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can just load the model if already trained and not run the grid search and best model again\n",
    "# in that case, do not run the next cells\n",
    "best_model = load_model('../data/flares_keras_RNN.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the model to classification only\n",
    "\n",
    "def build_flares_model(hparams):\n",
    "\n",
    "    units = hparams[\"units\"]\n",
    "    dropout = hparams[\"dropout\"]\n",
    "    layers_n = hparams[\"num_layers\"]\n",
    "    lr = hparams[\"lr\"]\n",
    "\n",
    "    inp = Input(shape=(hparams[\"timesteps\"], hparams[\"features\"]))\n",
    "    x = inp\n",
    "\n",
    "    \"\"\"for i in range(layers_n):\n",
    "        return_sequences = (i < layers_n - 1)\n",
    "        x = layers.LSTM(units, return_sequences=return_sequences)(x)\n",
    "        x = layers.Dropout(dropout)(x)\"\"\"\n",
    "\n",
    "    for i in range(layers_n):\n",
    "        return_sequences = (i < layers_n - 1)\n",
    "        x = layers.GRU(units, return_sequences=return_sequences)(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "\n",
    "\n",
    "    out = layers.Dense(hparams[\"num_classes\"], activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[2]\n",
    "\n",
    "inputs = Input(shape=(seq_len, n_features))\n",
    "x = Conv1D(64, kernel_size=3, padding=\"causal\", activation=\"relu\")(inputs)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = GRU(64, return_sequences=False)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "outputs = Dense(3, activation=\"softmax\")(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c2745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune hyperparameters\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "def flares_model_builder(hp):\n",
    "\n",
    "    hparams = {\n",
    "        \"units\": hp.Choice(\"units\", [32, 64, 128]),\n",
    "        \"dropout\": hp.Float(\"dropout\", 0.1, 0.5, step=0.1),\n",
    "        \"num_layers\": hp.Choice(\"num_layers\", [1, 2, 3]),\n",
    "        \"lr\": hp.Choice(\"lr\", [1e-4, 3e-4, 1e-3]),\n",
    "        \"timesteps\": X_train_scaled.shape[1],\n",
    "        \"features\": X_train_scaled.shape[2],\n",
    "        \"num_classes\": num_classes\n",
    "    }\n",
    "\n",
    "    return build_flares_model(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c1ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tuner (it may take a while...)\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=flares_model_builder,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=50,\n",
    "    overwrite=True,\n",
    "    directory=\"flare_tuning\",\n",
    "    project_name=\"rnn_flares\"\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    class_weight=class_weight_dict,\n",
    "    epochs=40,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5, restore_best_weights=True\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967438ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with best model\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "\n",
    "history = best_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weight_dict,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5, restore_best_weights=True\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "results = best_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(dict(zip(best_model.metrics_names, results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f1604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_model.save(\"../data/flares_keras_RNN.keras\")\n",
    "print(\"Best model saved to ../data/flares_keras_RNN.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_proba = best_model.predict(X_test_scaled).ravel()     # flatten probabilities\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)       # threshold at 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict (do NOT ravel multi-class outputs)\n",
    "y_pred_proba = best_model.predict(X_test_scaled)   # shape (n_samples, n_classes) for multi-class\n",
    "if y_pred_proba.ndim > 1:\n",
    "    # multi-class: take class with highest probability\n",
    "    y_pred_labels = np.argmax(y_pred_proba, axis=1)\n",
    "else:\n",
    "    # binary: threshold the single probability output\n",
    "    y_pred_labels = (y_pred_proba.ravel() >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d3ade1",
   "metadata": {},
   "source": [
    "# Results\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick debug: print shapes\n",
    "print(\"len(y_test) =\", len(y_test), \"len(y_pred_labels) =\", len(y_pred_labels))\n",
    "print(\"y_test.ndim =\", y_test.ndim, \"y_pred_labels.ndim =\", np.asarray(y_pred_labels).ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac1567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "# 1. Probabilities from NN\n",
    "y_pred_proba = best_model.predict(X_test)\n",
    "\n",
    "# 2. Convert to binary labels\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# 3. Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_labels)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 4. Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_labels))\n",
    "\n",
    "# 5. Additional metrics\n",
    "if len(np.unique(y_test)) > 1:\n",
    "    f2 = fbeta_score(y_test, y_pred_labels, beta=2, average='weighted')\n",
    "    f1 = fbeta_score(y_test, y_pred_labels, beta=1, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred_labels, average='weighted')\n",
    "    avg_prec = average_precision_score(y_test, y_pred_proba, average=\"macro\")\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "\n",
    "    metrics_table = pd.DataFrame({\n",
    "        'Metric': ['F2', 'F1', 'Recall', 'Avg Precision', 'ROC AUC'],\n",
    "        'Score': [f2, f1, recall, avg_prec, roc_auc]\n",
    "    })\n",
    "\n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    print(metrics_table.to_string(index=False, float_format=\"%.4f\"))\n",
    "else:\n",
    "    print(\"Only one class present in y_test. Metrics skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "plt.suptitle('Flare Forecast Using Neural Networks', fontsize=16, fontweight='bold')\n",
    "\n",
    "class_names = ['No Flare', 'Flare C', 'Flare M', 'Flare X']\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1, xticklabels=class_names, yticklabels=class_names)\n",
    "ax1.set_title('Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('True Label')\n",
    "ax1.set_xlabel('Predicted Label')\n",
    "\n",
    "# 2. Normalized Confusion Matrix\n",
    "cm_norm = pd.DataFrame(cm).apply(lambda x: x/sum(x), axis = 1)\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap='Blues', ax=ax2, xticklabels=class_names, yticklabels=class_names)\n",
    "ax2.set_title('Normalized Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('True Label')\n",
    "ax2.set_xlabel('Predicted Label')\n",
    "\n",
    "# 3. ROC Curve\n",
    "\n",
    "if len(np.unique(y_test)) > 1:\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "\n",
    "    # binarize true labels\n",
    "    y_test_bin = label_binarize(y_test, classes=[0,1,2,3]) # 0=0, C=1, M=2, X=3\n",
    "\n",
    "    for i in range(3):\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
    "        ax3.plot(fpr, tpr, label=f'Class {i} (AUC={auc(fpr, tpr):.3f})')\n",
    "    \n",
    "    #fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    ax3.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
    "    ax3.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "    ax3.set_xlabel('False Positive Rate')\n",
    "    ax3.set_ylabel('True Positive Rate')\n",
    "    ax3.set_title('ROC Curve', fontsize=12, fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Precision-Recall Curve\n",
    "if len(np.unique(y_test)) > 1:\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "\n",
    "    for i in range(3):\n",
    "        recall, precision, _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
    "        ax4.plot(recall, precision, label=f'Class {i} (AUC={auc(recall, precision):.3f})')\n",
    "\n",
    "    #precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    ax4.plot(recall, precision, linewidth=2, label=f'PR (AP = {avg_prec:.3f})')\n",
    "    ax4.axhline(y=y_test.mean(), color='k', linestyle='--', linewidth=1, \n",
    "                label=f'Baseline ({y_test.mean():.3f})')\n",
    "    ax4.set_xlabel('Recall')\n",
    "    ax4.set_ylabel('Precision')\n",
    "    ax4.set_title('Precision-Recall Curve', fontsize=12, fontweight='bold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Training and Validation Loss\n",
    "if 'history' in locals():\n",
    "    hist = history.history\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    ax5.plot(hist['loss'], label='Train Loss', linewidth=2)\n",
    "    if 'val_loss' in hist:\n",
    "        ax5.plot(hist['val_loss'], label='Val Loss', linewidth=2)\n",
    "    ax5.set_xlabel('Epoch')\n",
    "    ax5.set_ylabel('Loss')\n",
    "    ax5.set_title('Training and Validation Loss', fontsize=12, fontweight='bold')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Prediction Probability Distribution\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.hist(y_pred_proba[y_test == 0], bins=50, alpha=0.5, label='No Flare (True)', color=['blue', 'blue', 'blue', 'blue'])\n",
    "ax6.hist(y_pred_proba[y_test == 1], bins=50, alpha=0.5, label='Flare C (True)', color=['red', 'red', 'red', 'red'])\n",
    "ax6.hist(y_pred_proba[y_test == 2], bins=50, alpha=0.5, label='Flare M (True)', color=['red', 'red', 'red', 'red'])\n",
    "ax6.hist(y_pred_proba[y_test == 3], bins=50, alpha=0.5, label='Flare X (True)', color=['red', 'red', 'red', 'red'])\n",
    "ax6.set_xlabel('Predicted Probability')\n",
    "ax6.set_ylabel('Frequency')\n",
    "ax6.set_yscale('log')\n",
    "ax6.set_title('Distribution of Predicted Probabilities', fontsize=12, fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/solar_flare_RNN_results.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nVisualization saved as 'solar_flare_RNN_results.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d8a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
