{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc66fcb",
   "metadata": {},
   "source": [
    "# Forecasting solar flares using support vector machine for classification\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcde7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
    "                             roc_curve, precision_recall_curve, average_precision_score, \n",
    "                             fbeta_score, recall_score, make_scorer)\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a00a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw dataframe\n",
    "df = pd.read_csv(\"../data/data_flares.csv\")\n",
    "\n",
    "print(df.info())\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f77663",
   "metadata": {},
   "source": [
    "# Changing the dataframe to fit SVM\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9995b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'DATE' column is in datetime format\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze flare distribution over time\n",
    "# Number of C, M, and X flares per year\n",
    "\n",
    "sum_columns = ['Flares: C', 'Flares: M', 'Flares: X']\n",
    "df_flares = df.groupby(df['DATE'].dt.year)[sum_columns].agg(['sum'])\n",
    "#df_flares = df_flares.reset_index()\n",
    "print(df_flares)\n",
    "\n",
    "# Number of days with M or X flares\n",
    "yearly_flares = df.groupby(df['DATE'].dt.year)['flare_today'].agg(['sum', 'count', 'mean'])\n",
    "print(\"\\nDays with M or X flare distribution by year:\")\n",
    "print(yearly_flares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b756e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the lagged features to be used in the random forest model\n",
    "\n",
    "def create_lagged_features(df, n_days=3):\n",
    "    \"\"\"\n",
    "    Create features using the last n_days of data to predict tomorrow's flare.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df = df.sort_values('DATE').reset_index(drop=True)\n",
    "    \n",
    "    # Features to use (exclude DATE and target)\n",
    "    feature_cols = [col for col in df.columns if col not in ['DATE', 'flare_today']]\n",
    "    \n",
    "    # Create lagged features for each of the past n_days\n",
    "    lagged_df = pd.DataFrame(index=df.index) # important to keep the index for alignment\n",
    "    \n",
    "    for i in range(1, n_days + 1):\n",
    "        for col in feature_cols:\n",
    "            lagged_df[f'{col}_lag{i}'] = df[col].shift(i)\n",
    "    \n",
    "    # Target: tomorrow's flare (shift flare_today by -1)\n",
    "    lagged_df['target'] = df['flare_today'].shift(-1)\n",
    "    lagged_df['DATE'] = df['DATE']\n",
    "    \n",
    "    # Drop rows with NaN (first n_days rows and last row)\n",
    "    lagged_df = lagged_df.dropna()\n",
    "    \n",
    "    return lagged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the lagged features for the past 3 days\n",
    "lagged_data = create_lagged_features(df, n_days=3)\n",
    "\n",
    "print(lagged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d513715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chronological split is important for time series\n",
    "lagged_data = lagged_data.sort_values('DATE').reset_index(drop=True)\n",
    "assert lagged_data['DATE'].is_monotonic_increasing\n",
    "\n",
    "print(lagged_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16b26f",
   "metadata": {},
   "source": [
    "# Fitting the model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = lagged_data.drop(['target', 'DATE'], axis=1)\n",
    "y = lagged_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978fe000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets (chronological split is important for time series)\n",
    "# Use last 20% as test set\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Percentage of positive cases in train: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"Percentage of positive cases in test: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08597d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the training data\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "#print(f\"\\nAfter SMOTE:\")\n",
    "#print(f\"Training samples: {len(X_train_balanced)}\")\n",
    "#print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1460266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring metric\n",
    "scoring = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TimeSeriesSplit for cross-validation in time series data\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86602a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "# GridSearchCV with balanced and umbalanced data\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    #('smote', SMOTE(random_state=42)),\n",
    "    (\"svm\", SVC(class_weight='balanced', probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = [\n",
    "    {'svm__kernel': ['linear'], 'svm__C': [0.1, 1, 10, 100]},\n",
    "    {'svm__kernel': ['rbf'], 'svm__C': [0.1, 1, 10, 100], 'svm__gamma': ['scale', 0.01, 0.001]},\n",
    "    {'svm__kernel': ['poly'], 'svm__C': [0.1, 1, 10, 100], 'svm__gamma': ['scale', 0.01, 0.001]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dde025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can just load the model if already trained and not run the grid search and best model again\n",
    "# in that case, do not run the next two cells\n",
    "best_svm = joblib.load(\"../data/flares_best_SVM.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the best hyperparameters\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=tscv,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nStarting grid search for SVM (this may take a while)...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62356ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best parameters on scaled data\n",
    "best_svm = grid_search.best_estimator_  # pipeline with scaler + best SVM\n",
    "best_svm.fit(X_train_scaled, y_train)\n",
    "print(best_svm.named_steps['svm'])\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_svm, \"../data/flares_best_SVM.pkl\")\n",
    "print(\"Best model saved to ../data/flares_best_SVM.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac6eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = best_svm.predict(X_test_scaled)\n",
    "y_pred_proba = best_svm.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b245a405",
   "metadata": {},
   "source": [
    "# Results\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac1567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "if len(np.unique(y_test)) > 1:\n",
    "    f2_score = fbeta_score(y_test, y_pred, beta=2)\n",
    "    f1_score = fbeta_score(y_test, y_pred, beta=1)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"Average F2 Score: {f2_score:.4f}\")\n",
    "    print(f\"Average F1 Score: {f1_score:.4f}\")\n",
    "    print(f\"Average Recall Score: {recall:.4f}\")\n",
    "    print(f\"Average Precision Score: {avg_precision:.4f}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "plt.suptitle('Flare Forecast Using Support Vector Machine', fontsize=16, fontweight='bold')\n",
    "\n",
    "class_names = ['No Flare', 'Flare']\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1, xticklabels=class_names, yticklabels=class_names)\n",
    "ax1.set_title('Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('True Label')\n",
    "ax1.set_xlabel('Predicted Label')\n",
    "\n",
    "# 2. Normalized Confusion Matrix\n",
    "cm_norm = pd.DataFrame(cm).apply(lambda x: x/sum(x), axis = 1)\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap='Blues', ax=ax2, xticklabels=class_names, yticklabels=class_names)\n",
    "ax2.set_title('Normalized Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('True Label')\n",
    "ax2.set_xlabel('Predicted Label')\n",
    "\n",
    "# 3. ROC Curve\n",
    "if len(np.unique(y_test)) > 1:\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    ax3.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
    "    ax3.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "    ax3.set_xlabel('False Positive Rate')\n",
    "    ax3.set_ylabel('True Positive Rate')\n",
    "    ax3.set_title('ROC Curve', fontsize=12, fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Precision-Recall Curve\n",
    "if len(np.unique(y_test)) > 1:\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    ax4.plot(recall, precision, linewidth=2, label=f'PR (AP = {avg_precision:.3f})')\n",
    "    ax4.axhline(y=y_test.mean(), color='k', linestyle='--', linewidth=1, \n",
    "                label=f'Baseline ({y_test.mean():.3f})')\n",
    "    ax4.set_xlabel('Recall')\n",
    "    ax4.set_ylabel('Precision')\n",
    "    ax4.set_title('Precision-Recall Curve', fontsize=12, fontweight='bold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Prediction Probability Distribution\n",
    "ax6 = plt.subplot(2, 3, 5)\n",
    "ax6.hist(y_pred_proba[y_test == 0], bins=50, alpha=0.5, label='No Flare (True)', color='blue')\n",
    "ax6.hist(y_pred_proba[y_test == 1], bins=50, alpha=0.5, label='Flare (True)', color='red')\n",
    "ax6.set_xlabel('Predicted Probability')\n",
    "ax6.set_ylabel('Frequency')\n",
    "ax6.set_yscale('log')\n",
    "ax6.set_title('Distribution of Predicted Probabilities', fontsize=12, fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/solar_flare_SVM_results.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nVisualization saved as 'solar_flare_SVM_results.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6be792",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba >= thresh).astype(int)\n",
    "    cm_thresh = confusion_matrix(y_test, y_pred_thresh)\n",
    "    tn, fp, fn, tp = cm_thresh.ravel() if cm_thresh.size == 4 else (cm_thresh[0,0], 0, 0, 0)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    print(f\"\\nThreshold = {thresh}\")\n",
    "    print(f\"  TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\")\n",
    "    print(f\"  Precision: {precision:.3f}, Recall: {recall:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
