{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc66fcb",
   "metadata": {},
   "source": [
    "# Forecasting geomagnetic storms using recurrent neural networks for multi-class classification\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcde7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
    "                             roc_curve, precision_recall_curve, average_precision_score, \n",
    "                             fbeta_score, recall_score)\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras import Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a00a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw dataframe\n",
    "df = pd.read_csv(\"../data/data_storms.csv\")\n",
    "\n",
    "print(df.info())\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f77663",
   "metadata": {},
   "source": [
    "# Changing the dataframe to fit NN\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9995b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'datetime' column is in datetime format\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze storm distribution over time\n",
    "\n",
    "# Number of storm-hours per year\n",
    "df_storms = df.groupby(df['datetime'].dt.year)['storm_now'].agg(['sum'])\n",
    "print(df_storms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b756e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hours with storms (count should be 8760 [24*365] or 8784 for leap years)\n",
    "yearly_storms = df.groupby(df['datetime'].dt.year)['storm_now'].agg(['sum', 'count'])\n",
    "print(\"\\nHours with storm distribution by year:\")\n",
    "print(yearly_storms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_features(df, n_hours=3):\n",
    "    \"\"\"\n",
    "    Create features using the last n_hours of data to predict the next hour's storm.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime').reset_index(drop=True)\n",
    "    \n",
    "    # Features to use (exclude datetime and target)\n",
    "    feature_cols = [col for col in df.columns if col not in ['datetime', 'storm_now']]\n",
    "    \n",
    "    # Create lagged features for each of the past n_hours\n",
    "    lagged_df = pd.DataFrame(index=df.index) # important to keep the index for alignment\n",
    "    \n",
    "    for i in range(1, n_hours + 1):\n",
    "        for col in feature_cols:\n",
    "            lagged_df[f'{col}_lag{i}'] = df[col].shift(i)\n",
    "    \n",
    "    # Target: next hour's storm (shift storm_now by -1)\n",
    "    lagged_df['target'] = df['storm_now'].shift(-1)\n",
    "    lagged_df['datetime'] = df['datetime']\n",
    "    \n",
    "    # Drop rows with NaN (first n_hours rows and last row)\n",
    "    lagged_df = lagged_df.dropna()\n",
    "    \n",
    "    return lagged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d513715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the lagged features for the past 3 hours\n",
    "lagged_data = create_lagged_features(df, n_hours=3)\n",
    "\n",
    "print(lagged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f5298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chronological split is important for time series\n",
    "lagged_data = lagged_data.sort_values('datetime').reset_index(drop=True)\n",
    "assert lagged_data['datetime'].is_monotonic_increasing\n",
    "\n",
    "print(lagged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b447ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check all columns to dorp some on the next step\n",
    "print(lagged_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a80880",
   "metadata": {},
   "source": [
    "# Fitting the model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# I started using the DST feature, and it is be very useful, but it is not always available in real-time forecasts\n",
    "#X = lagged_data.drop(['datetime', 'target', 'DST_lag1', 'DST_lag2', 'DST_lag3'], axis=1)\n",
    "X = lagged_data.drop(['datetime', 'target'], axis=1)\n",
    "y = lagged_data['target']\n",
    "\n",
    "print(X.info(), y.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978fe000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "\n",
    "# Use last 20% as test set\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Percentage of positive cases in train: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"Percentage of positive cases in test: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e27b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the training data\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "#print(f\"\\nAfter SMOTE:\")\n",
    "#print(f\"Training samples: {len(X_train_balanced)}\")\n",
    "#print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e751770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can just load the model if already trained and not run the grid search and best model again\n",
    "# in that case, do not run the next two cells\n",
    "model = load_model('./Data/flares_keras.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_features, layer1_units=128, layer2_units=64, \n",
    "                 dropout_rate=0.3, learning_rate=0.001):\n",
    "    \"\"\"Create model with configurable hyperparameters\"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=(n_features,)),\n",
    "        Dense(layer1_units, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(layer2_units, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['Precision', 'Recall', 'AUC']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f99f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_search(X_train_scaled, y_train, n_iter=20):\n",
    "    \"\"\"Random search over hyperparameters\"\"\"\n",
    "    \n",
    "    # Define hyperparameter ranges\n",
    "    param_distributions = {\n",
    "        'layer1_units': [64, 128, 256, 512],\n",
    "        'layer2_units': [32, 64, 128, 256],\n",
    "        'dropout_rate': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        'learning_rate': [0.0001, 0.0005, 0.001, 0.005, 0.01],\n",
    "        'batch_size': [16, 32, 64, 128]\n",
    "    }\n",
    "    \n",
    "    n_features = X_train_scaled.shape[1]\n",
    "    \n",
    "    # Compute class weights once\n",
    "    class_weights = dict(enumerate(compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )))\n",
    "    \n",
    "    best_score = 0\n",
    "    best_params = {}\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Testing {n_iter} random combinations...\")\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        # Random sample from each parameter\n",
    "        params = {\n",
    "            'layer1_units': np.random.choice(param_distributions['layer1_units']),\n",
    "            'layer2_units': np.random.choice(param_distributions['layer2_units']),\n",
    "            'dropout_rate': np.random.choice(param_distributions['dropout_rate']),\n",
    "            'learning_rate': np.random.choice(param_distributions['learning_rate']),\n",
    "            'batch_size': np.random.choice(param_distributions['batch_size'])\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n[{i+1}/{n_iter}] Testing: {params}\")\n",
    "        \n",
    "        # Create model (exclude batch_size from model creation)\n",
    "        model_params = {k: v for k, v in params.items() if k != 'batch_size'}\n",
    "        model = create_model(n_features=n_features, **model_params)\n",
    "        \n",
    "        es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            validation_split=0.2,\n",
    "            epochs=100,\n",
    "            batch_size=params['batch_size'],\n",
    "            callbacks=[es],\n",
    "            verbose=0,\n",
    "            class_weight=class_weights\n",
    "        )\n",
    "        \n",
    "        # Get best validation AUC\n",
    "        val_auc = max(history.history['val_AUC'])\n",
    "        print(f\"  -> Val AUC: {val_auc:.4f}\")\n",
    "        \n",
    "        # Store results\n",
    "        results.append({**params, 'val_auc': val_auc})\n",
    "        \n",
    "        # Update best\n",
    "        if val_auc > best_score:\n",
    "            best_score = val_auc\n",
    "            best_params = params\n",
    "    \n",
    "    print(\"Best Parameters:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(f\"  Best Validation AUC: {best_score:.4f}\")\n",
    "    \n",
    "    return best_params, best_score, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd54b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the best hyperparameters\n",
    "best_params, best_score, results = randomized_search(\n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    n_iter=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620637ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of features\n",
    "n_features = X_train_scaled.shape[1]\n",
    "\n",
    "# Create model with best parameters\n",
    "model = Sequential([\n",
    "    Input(shape=(n_features,)),\n",
    "    Dense(best_params['layer1_units'], activation='relu'),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(best_params['layer2_units'], activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with best learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['Precision', 'Recall', 'AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9c0818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = dict(enumerate(compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70146f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with best batch size\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=best_params['batch_size'],\n",
    "    callbacks=[es],\n",
    "    verbose=1,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "results = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(dict(zip(model.metrics_names, results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d8e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model.save(\"../data/flares_keras.keras\")\n",
    "print(\"Best model saved to ../data/flares_keras.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_proba = model.predict(X_test_scaled).ravel()     # flatten probabilities\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)       # threshold at 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5632a",
   "metadata": {},
   "source": [
    "# Results\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9049289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "if len(np.unique(y_test)) > 1:\n",
    "    f2_score = fbeta_score(y_test, y_pred, beta=2)\n",
    "    f1_score = fbeta_score(y_test, y_pred, beta=1)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    metrics_table = pd.DataFrame({\n",
    "        'Metric': ['F2', 'F1', 'Recall', 'Avg Precision', 'ROC AUC'],\n",
    "        'Score': [f2_score, f1_score, recall, avg_precision, roc_auc]\n",
    "    })\n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    print(metrics_table.to_string(index=False, float_format=\"%.4f\"))\n",
    "else:\n",
    "    print(\"Only one class present in y_test. Metrics skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "plt.suptitle('Geomagnetic Storm Forecast Using Neural Networks', fontsize=16, fontweight='bold')\n",
    "\n",
    "class_names = ['No Storm', 'Storm']\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1, xticklabels=class_names, yticklabels=class_names)\n",
    "ax1.set_title('Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('True Label')\n",
    "ax1.set_xlabel('Predicted Label')\n",
    "\n",
    "# 2. Normalized Confusion Matrix\n",
    "cm_norm = pd.DataFrame(cm).apply(lambda x: x/sum(x), axis = 1)\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap='Blues', ax=ax2, xticklabels=class_names, yticklabels=class_names)\n",
    "ax2.set_title('Normalized Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('True Label')\n",
    "ax2.set_xlabel('Predicted Label')\n",
    "\n",
    "# 3. ROC Curve\n",
    "if len(np.unique(y_test)) > 1:\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    ax3.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
    "    ax3.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "    ax3.set_xlabel('False Positive Rate')\n",
    "    ax3.set_ylabel('True Positive Rate')\n",
    "    ax3.set_title('ROC Curve', fontsize=12, fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Precision-Recall Curve\n",
    "if len(np.unique(y_test)) > 1:\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    ax4.plot(recall, precision, linewidth=2, label=f'PR (AP = {avg_precision:.3f})')\n",
    "    ax4.axhline(y=y_test.mean(), color='k', linestyle='--', linewidth=1, \n",
    "                label=f'Baseline ({y_test.mean():.3f})')\n",
    "    ax4.set_xlabel('Recall')\n",
    "    ax4.set_ylabel('Precision')\n",
    "    ax4.set_title('Precision-Recall Curve', fontsize=12, fontweight='bold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Training and Validation Loss\n",
    "if 'history' in locals():\n",
    "    hist = history.history\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    ax5.plot(hist['loss'], label='Train Loss', linewidth=2)\n",
    "    if 'val_loss' in hist:\n",
    "        ax5.plot(hist['val_loss'], label='Val Loss', linewidth=2)\n",
    "    ax5.set_xlabel('Epoch')\n",
    "    ax5.set_ylabel('Loss')\n",
    "    ax5.set_title('Training and Validation Loss', fontsize=12, fontweight='bold')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Prediction Probability Distribution\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.hist(y_pred_proba[y_test == 0], bins=50, alpha=0.5, label='No Storm (True)', color='blue')\n",
    "ax6.hist(y_pred_proba[y_test == 1], bins=50, alpha=0.5, label='Storm (True)', color='red')\n",
    "ax6.set_xlabel('Predicted Probability')\n",
    "ax6.set_ylabel('Frequency')\n",
    "ax6.set_yscale('log')\n",
    "ax6.set_title('Distribution of Predicted Probabilities', fontsize=12, fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/geomag_storm_NN_results.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nVisualization saved as 'geomag_storm_NN_results.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba >= thresh).astype(int)\n",
    "    cm_thresh = confusion_matrix(y_test, y_pred_thresh)\n",
    "    tn, fp, fn, tp = cm_thresh.ravel() if cm_thresh.size == 4 else (cm_thresh[0,0], 0, 0, 0)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    print(f\"\\nThreshold = {thresh}\")\n",
    "    print(f\"  TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\")\n",
    "    print(f\"  Precision: {precision:.3f}, Recall: {recall:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
